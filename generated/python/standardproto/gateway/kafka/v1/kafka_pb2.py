# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: gateway/kafka/v1/kafka.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import any_pb2 as google_dot_protobuf_dot_any__pb2
from validate import validate_pb2 as validate_dot_validate__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1cgateway/kafka/v1/kafka.proto\x12\x12generated.kafka.v1\x1a\x19google/protobuf/any.proto\x1a\x17validate/validate.proto\"\x96\x01\n\nKafkaEvent\x12 \n\x05topic\x18\x01 \x01(\tB\n\xfa\x42\x07r\x05\x10\x01\xd0\x01\x00R\x05topic\x12\x30\n\x03key\x18\x02 \x01(\x0b\x32\x14.google.protobuf.AnyB\x08\xfa\x42\x05\x8a\x01\x02\x10\x01R\x03key\x12\x34\n\x05value\x18\x03 \x01(\x0b\x32\x14.google.protobuf.AnyB\x08\xfa\x42\x05\x8a\x01\x02\x10\x01R\x05value\"\x96\x01\n\x12\x43onsumedKafkaEvent\x12\x14\n\x05topic\x18\x01 \x01(\tR\x05topic\x12\x1c\n\tpartition\x18\x02 \x01(\x04R\tpartition\x12\x16\n\x06offset\x18\x03 \x01(\x04R\x06offset\x12\x34\n\x05\x65vent\x18\x04 \x01(\x0b\x32\x1e.generated.kafka.v1.KafkaEventR\x05\x65vent\"6\n\x12RandomPartitionKey\x12 \n\x05value\x18\x01 \x01(\x05\x42\n\xfa\x42\x07\x1a\x05\x10\x80\x02(\x00R\x05valueB+Z)github.com/wrossmorrow/generated.kafka.v1b\x06proto3')



_KAFKAEVENT = DESCRIPTOR.message_types_by_name['KafkaEvent']
_CONSUMEDKAFKAEVENT = DESCRIPTOR.message_types_by_name['ConsumedKafkaEvent']
_RANDOMPARTITIONKEY = DESCRIPTOR.message_types_by_name['RandomPartitionKey']
KafkaEvent = _reflection.GeneratedProtocolMessageType('KafkaEvent', (_message.Message,), {
  'DESCRIPTOR' : _KAFKAEVENT,
  '__module__' : 'gateway.kafka.v1.kafka_pb2'
  # @@protoc_insertion_point(class_scope:generated.kafka.v1.KafkaEvent)
  })
_sym_db.RegisterMessage(KafkaEvent)

ConsumedKafkaEvent = _reflection.GeneratedProtocolMessageType('ConsumedKafkaEvent', (_message.Message,), {
  'DESCRIPTOR' : _CONSUMEDKAFKAEVENT,
  '__module__' : 'gateway.kafka.v1.kafka_pb2'
  # @@protoc_insertion_point(class_scope:generated.kafka.v1.ConsumedKafkaEvent)
  })
_sym_db.RegisterMessage(ConsumedKafkaEvent)

RandomPartitionKey = _reflection.GeneratedProtocolMessageType('RandomPartitionKey', (_message.Message,), {
  'DESCRIPTOR' : _RANDOMPARTITIONKEY,
  '__module__' : 'gateway.kafka.v1.kafka_pb2'
  # @@protoc_insertion_point(class_scope:generated.kafka.v1.RandomPartitionKey)
  })
_sym_db.RegisterMessage(RandomPartitionKey)

if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z)github.com/wrossmorrow/generated.kafka.v1'
  _KAFKAEVENT.fields_by_name['topic']._options = None
  _KAFKAEVENT.fields_by_name['topic']._serialized_options = b'\372B\007r\005\020\001\320\001\000'
  _KAFKAEVENT.fields_by_name['key']._options = None
  _KAFKAEVENT.fields_by_name['key']._serialized_options = b'\372B\005\212\001\002\020\001'
  _KAFKAEVENT.fields_by_name['value']._options = None
  _KAFKAEVENT.fields_by_name['value']._serialized_options = b'\372B\005\212\001\002\020\001'
  _RANDOMPARTITIONKEY.fields_by_name['value']._options = None
  _RANDOMPARTITIONKEY.fields_by_name['value']._serialized_options = b'\372B\007\032\005\020\200\002(\000'
  _KAFKAEVENT._serialized_start=105
  _KAFKAEVENT._serialized_end=255
  _CONSUMEDKAFKAEVENT._serialized_start=258
  _CONSUMEDKAFKAEVENT._serialized_end=408
  _RANDOMPARTITIONKEY._serialized_start=410
  _RANDOMPARTITIONKEY._serialized_end=464
# @@protoc_insertion_point(module_scope)
